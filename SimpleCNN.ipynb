{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build train and test data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import blob_log\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in all the augmented and noisy images\n",
    "path = \"./Multislice\"\n",
    "folders=os.listdir(path) \n",
    "data=[]    #all the images will be stored in this list.\n",
    "defecttype=[]    #all the defect type corresponding to each image store in this list\n",
    "defects={'Sw':0,'Mo':1,'W2s2':2,'Vw':3,'Vs2':4,'Ws':5}     # each int represents a defect type\n",
    "\n",
    "for folder in folders:  #traversing all subfolders(types of defects) in MULTISLICE\n",
    "    if '.' in folder:   #make sure it will not traverse file like '.DS_store'\n",
    "        continue\n",
    "    \n",
    "    noisy_path = \"./Multislice\"+\"/\"+folder+'/'+folder+'_Augmented' \n",
    "    filelist = glob.glob(noisy_path+'/*.png')\n",
    "    data.extend([img_to_array(load_img(fname, grayscale = True)) for fname in filelist])\n",
    "    defecttype.extend([defects[folder]]*len(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51125, 64, 64, 1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## there should be 51125 images, each image with size of (64,64,1)\n",
    "np.array(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "\n",
    "### We might want to try Suffle split to reduce bias in the test train split \n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(data), defecttype, test_size = 0.2, random_state = 28956)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 6\n",
    "#epochs = 50\n",
    "\n",
    "# input image dimensions\n",
    "img_x, img_y = 64, 64\n",
    "input_shape = (img_x, img_y, 1)\n",
    "\n",
    "# Normalizing data\n",
    "x_train = (x_train - np.amin(x_train))/(np.amax(x_train) - np.amin(x_train))\n",
    "x_test = (x_test - np.amin(x_test))/(np.amax(x_test) - np.amin(x_test))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "##### add layers to CNN model: \n",
    "model.add(Conv2D(16,kernel_size=(5,5),strides=(1,1),activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#model.add(Conv2D(16,(5,5),activation='relu'))\n",
    "#model.add(Conv2D(16,(3,3),activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(5,5),activation='relu'))\n",
    "#model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(5,5),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "######\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40900 samples, validate on 10225 samples\n",
      "Epoch 1/120\n",
      "40900/40900 [==============================] - 138s 3ms/step - loss: 1.7809 - acc: 0.1835 - val_loss: 1.7792 - val_acc: 0.1913\n",
      "Epoch 2/120\n",
      "40900/40900 [==============================] - 137s 3ms/step - loss: 1.7772 - acc: 0.1930 - val_loss: 1.7745 - val_acc: 0.1796\n",
      "Epoch 3/120\n",
      "40900/40900 [==============================] - 151s 4ms/step - loss: 1.7730 - acc: 0.1970 - val_loss: 1.7699 - val_acc: 0.2404\n",
      "Epoch 4/120\n",
      "40900/40900 [==============================] - 154s 4ms/step - loss: 1.7664 - acc: 0.2145 - val_loss: 1.7594 - val_acc: 0.3290\n",
      "Epoch 5/120\n",
      "40900/40900 [==============================] - 155s 4ms/step - loss: 1.7535 - acc: 0.2565 - val_loss: 1.7431 - val_acc: 0.3021\n",
      "Epoch 6/120\n",
      "40900/40900 [==============================] - 154s 4ms/step - loss: 1.7275 - acc: 0.2917 - val_loss: 1.7042 - val_acc: 0.3948\n",
      "Epoch 7/120\n",
      "40900/40900 [==============================] - 137s 3ms/step - loss: 1.6680 - acc: 0.3106 - val_loss: 1.6185 - val_acc: 0.2880\n",
      "Epoch 8/120\n",
      "40900/40900 [==============================] - 125s 3ms/step - loss: 1.5588 - acc: 0.3442 - val_loss: 1.4807 - val_acc: 0.3363\n",
      "Epoch 9/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 1.4281 - acc: 0.4021 - val_loss: 1.3958 - val_acc: 0.4246\n",
      "Epoch 10/120\n",
      "40900/40900 [==============================] - 128s 3ms/step - loss: 1.2732 - acc: 0.4844 - val_loss: 1.2654 - val_acc: 0.4265\n",
      "Epoch 11/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 1.1231 - acc: 0.5450 - val_loss: 1.0602 - val_acc: 0.5709\n",
      "Epoch 12/120\n",
      "40900/40900 [==============================] - 129s 3ms/step - loss: 1.0078 - acc: 0.5867 - val_loss: 1.0380 - val_acc: 0.4935\n",
      "Epoch 13/120\n",
      "40900/40900 [==============================] - 144s 4ms/step - loss: 0.9194 - acc: 0.6209 - val_loss: 1.2995 - val_acc: 0.4642\n",
      "Epoch 14/120\n",
      "40900/40900 [==============================] - 144s 4ms/step - loss: 0.8405 - acc: 0.6505 - val_loss: 0.8197 - val_acc: 0.6321\n",
      "Epoch 15/120\n",
      "40900/40900 [==============================] - 160s 4ms/step - loss: 0.7717 - acc: 0.6847 - val_loss: 0.9167 - val_acc: 0.6392\n",
      "Epoch 16/120\n",
      "40900/40900 [==============================] - 184s 5ms/step - loss: 0.7072 - acc: 0.7068 - val_loss: 0.8044 - val_acc: 0.6887\n",
      "Epoch 17/120\n",
      "40900/40900 [==============================] - 192s 5ms/step - loss: 0.6599 - acc: 0.7250 - val_loss: 0.8805 - val_acc: 0.6779\n",
      "Epoch 18/120\n",
      "40900/40900 [==============================] - 198s 5ms/step - loss: 0.7516 - acc: 0.7004 - val_loss: 0.6622 - val_acc: 0.7430\n",
      "Epoch 19/120\n",
      "40900/40900 [==============================] - 141s 3ms/step - loss: 0.6159 - acc: 0.7429 - val_loss: 0.7905 - val_acc: 0.6484\n",
      "Epoch 20/120\n",
      "40900/40900 [==============================] - 137s 3ms/step - loss: 0.8415 - acc: 0.7097 - val_loss: 0.7149 - val_acc: 0.6649\n",
      "Epoch 21/120\n",
      "40900/40900 [==============================] - 137s 3ms/step - loss: 0.5784 - acc: 0.7600 - val_loss: 0.5485 - val_acc: 0.7570\n",
      "Epoch 22/120\n",
      "40900/40900 [==============================] - 142s 3ms/step - loss: 0.5288 - acc: 0.7805 - val_loss: 0.6160 - val_acc: 0.7550\n",
      "Epoch 23/120\n",
      "40900/40900 [==============================] - 129s 3ms/step - loss: 0.5056 - acc: 0.7905 - val_loss: 0.5025 - val_acc: 0.7763\n",
      "Epoch 24/120\n",
      "40900/40900 [==============================] - 124s 3ms/step - loss: 0.4968 - acc: 0.7918 - val_loss: 0.4868 - val_acc: 0.7853\n",
      "Epoch 25/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.4610 - acc: 0.8095 - val_loss: 0.4553 - val_acc: 0.8091\n",
      "Epoch 26/120\n",
      "40900/40900 [==============================] - 141s 3ms/step - loss: 0.4427 - acc: 0.8134 - val_loss: 0.5323 - val_acc: 0.7693\n",
      "Epoch 27/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.4357 - acc: 0.8184 - val_loss: 0.4359 - val_acc: 0.8099\n",
      "Epoch 28/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.4212 - acc: 0.8256 - val_loss: 0.4839 - val_acc: 0.7855\n",
      "Epoch 29/120\n",
      "40900/40900 [==============================] - 129s 3ms/step - loss: 0.4101 - acc: 0.8302 - val_loss: 0.5030 - val_acc: 0.7800\n",
      "Epoch 30/120\n",
      "40900/40900 [==============================] - 132s 3ms/step - loss: 0.4002 - acc: 0.8338 - val_loss: 0.3727 - val_acc: 0.8456\n",
      "Epoch 31/120\n",
      "40900/40900 [==============================] - 136s 3ms/step - loss: 0.3896 - acc: 0.8404 - val_loss: 0.3865 - val_acc: 0.8378\n",
      "Epoch 32/120\n",
      "40900/40900 [==============================] - 130s 3ms/step - loss: 0.3804 - acc: 0.8447 - val_loss: 0.3866 - val_acc: 0.8346\n",
      "Epoch 33/120\n",
      "40900/40900 [==============================] - 133s 3ms/step - loss: 0.5522 - acc: 0.8138 - val_loss: 0.3739 - val_acc: 0.8486\n",
      "Epoch 34/120\n",
      "40900/40900 [==============================] - 136s 3ms/step - loss: 0.3763 - acc: 0.8463 - val_loss: 0.3500 - val_acc: 0.8577\n",
      "Epoch 35/120\n",
      "40900/40900 [==============================] - 130s 3ms/step - loss: 0.3619 - acc: 0.8509 - val_loss: 0.3661 - val_acc: 0.8493\n",
      "Epoch 36/120\n",
      "40900/40900 [==============================] - 130s 3ms/step - loss: 0.3551 - acc: 0.8550 - val_loss: 0.4368 - val_acc: 0.8006\n",
      "Epoch 37/120\n",
      "40900/40900 [==============================] - 130s 3ms/step - loss: 0.3390 - acc: 0.8624 - val_loss: 0.3682 - val_acc: 0.8441\n",
      "Epoch 38/120\n",
      "40900/40900 [==============================] - 129s 3ms/step - loss: 0.3384 - acc: 0.8616 - val_loss: 0.3541 - val_acc: 0.8542\n",
      "Epoch 39/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.3315 - acc: 0.8676 - val_loss: 0.3239 - val_acc: 0.8652\n",
      "Epoch 40/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.3264 - acc: 0.8667 - val_loss: 0.3920 - val_acc: 0.8341\n",
      "Epoch 41/120\n",
      "40900/40900 [==============================] - 130s 3ms/step - loss: 0.3177 - acc: 0.8721 - val_loss: 0.3140 - val_acc: 0.8741\n",
      "Epoch 42/120\n",
      "40900/40900 [==============================] - 129s 3ms/step - loss: 0.3153 - acc: 0.8722 - val_loss: 0.3029 - val_acc: 0.8821\n",
      "Epoch 43/120\n",
      "40900/40900 [==============================] - 134s 3ms/step - loss: 0.3154 - acc: 0.8729 - val_loss: 0.3166 - val_acc: 0.8713\n",
      "Epoch 44/120\n",
      "40900/40900 [==============================] - 131s 3ms/step - loss: 0.3067 - acc: 0.8758 - val_loss: 0.2985 - val_acc: 0.8841\n",
      "Epoch 45/120\n",
      "40900/40900 [==============================] - 128s 3ms/step - loss: 0.2955 - acc: 0.8811 - val_loss: 0.3063 - val_acc: 0.8773\n",
      "Epoch 46/120\n",
      "40900/40900 [==============================] - 125s 3ms/step - loss: 0.2981 - acc: 0.8809 - val_loss: 0.3137 - val_acc: 0.8646\n",
      "Epoch 47/120\n",
      "40900/40900 [==============================] - 128s 3ms/step - loss: 0.2913 - acc: 0.8835 - val_loss: 0.3190 - val_acc: 0.8710\n",
      "Epoch 48/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2863 - acc: 0.8845 - val_loss: 0.3744 - val_acc: 0.8400\n",
      "Epoch 49/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2837 - acc: 0.8861 - val_loss: 0.2847 - val_acc: 0.8857\n",
      "Epoch 50/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.2798 - acc: 0.8876 - val_loss: 0.3232 - val_acc: 0.8646\n",
      "Epoch 51/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2765 - acc: 0.8903 - val_loss: 0.2882 - val_acc: 0.8856\n",
      "Epoch 52/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2795 - acc: 0.8886 - val_loss: 0.3093 - val_acc: 0.8680\n",
      "Epoch 53/120\n",
      "40900/40900 [==============================] - 128s 3ms/step - loss: 0.2674 - acc: 0.8931 - val_loss: 0.2548 - val_acc: 0.8996\n",
      "Epoch 54/120\n",
      "40900/40900 [==============================] - 129s 3ms/step - loss: 0.2671 - acc: 0.8923 - val_loss: 0.3083 - val_acc: 0.8704\n",
      "Epoch 55/120\n",
      "40900/40900 [==============================] - 128s 3ms/step - loss: 0.2656 - acc: 0.8945 - val_loss: 0.3028 - val_acc: 0.8736\n",
      "Epoch 56/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.2591 - acc: 0.8979 - val_loss: 0.2765 - val_acc: 0.8834\n",
      "Epoch 57/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2499 - acc: 0.9011 - val_loss: 0.3178 - val_acc: 0.8687\n",
      "Epoch 58/120\n",
      "40900/40900 [==============================] - 125s 3ms/step - loss: 0.2583 - acc: 0.8981 - val_loss: 0.4223 - val_acc: 0.8232\n",
      "Epoch 59/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.2529 - acc: 0.8996 - val_loss: 0.2785 - val_acc: 0.8814\n",
      "Epoch 60/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.2482 - acc: 0.9033 - val_loss: 0.2504 - val_acc: 0.8972\n",
      "Epoch 61/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2433 - acc: 0.9047 - val_loss: 0.2880 - val_acc: 0.8726\n",
      "Epoch 62/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2458 - acc: 0.9019 - val_loss: 0.3279 - val_acc: 0.8633\n",
      "Epoch 63/120\n",
      "40900/40900 [==============================] - 128s 3ms/step - loss: 0.2381 - acc: 0.9045 - val_loss: 0.2681 - val_acc: 0.8910\n",
      "Epoch 64/120\n",
      "40900/40900 [==============================] - 128s 3ms/step - loss: 0.2432 - acc: 0.9049 - val_loss: 0.2326 - val_acc: 0.9084\n",
      "Epoch 65/120\n",
      "40900/40900 [==============================] - 132s 3ms/step - loss: 0.2400 - acc: 0.9038 - val_loss: 0.2595 - val_acc: 0.8986\n",
      "Epoch 66/120\n",
      "40900/40900 [==============================] - 130s 3ms/step - loss: 0.2460 - acc: 0.9040 - val_loss: 0.2447 - val_acc: 0.9001\n",
      "Epoch 67/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2326 - acc: 0.9087 - val_loss: 0.2511 - val_acc: 0.8964\n",
      "Epoch 68/120\n",
      "40900/40900 [==============================] - 129s 3ms/step - loss: 0.2308 - acc: 0.9087 - val_loss: 0.3100 - val_acc: 0.8703\n",
      "Epoch 69/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2255 - acc: 0.9113 - val_loss: 0.2252 - val_acc: 0.9119\n",
      "Epoch 70/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2231 - acc: 0.9122 - val_loss: 0.2601 - val_acc: 0.8914\n",
      "Epoch 71/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.2195 - acc: 0.9139 - val_loss: 0.2573 - val_acc: 0.8890\n",
      "Epoch 72/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.2229 - acc: 0.9132 - val_loss: 0.2704 - val_acc: 0.8884\n",
      "Epoch 73/120\n",
      "40900/40900 [==============================] - 130s 3ms/step - loss: 0.2249 - acc: 0.9113 - val_loss: 0.2522 - val_acc: 0.8975\n",
      "Epoch 74/120\n",
      "40900/40900 [==============================] - 131s 3ms/step - loss: 0.2165 - acc: 0.9138 - val_loss: 0.2376 - val_acc: 0.9000\n",
      "Epoch 75/120\n",
      "40900/40900 [==============================] - 133s 3ms/step - loss: 0.2136 - acc: 0.9149 - val_loss: 0.2544 - val_acc: 0.8969\n",
      "Epoch 76/120\n",
      "40900/40900 [==============================] - 131s 3ms/step - loss: 0.2145 - acc: 0.9161 - val_loss: 0.3393 - val_acc: 0.8663\n",
      "Epoch 77/120\n",
      "40900/40900 [==============================] - 130s 3ms/step - loss: 0.2157 - acc: 0.9155 - val_loss: 0.2107 - val_acc: 0.9147\n",
      "Epoch 78/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2043 - acc: 0.9203 - val_loss: 0.2119 - val_acc: 0.9167\n",
      "Epoch 79/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.2115 - acc: 0.9169 - val_loss: 0.3298 - val_acc: 0.8594\n",
      "Epoch 80/120\n",
      "40900/40900 [==============================] - 128s 3ms/step - loss: 0.2065 - acc: 0.9186 - val_loss: 0.2304 - val_acc: 0.9059\n",
      "Epoch 81/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2085 - acc: 0.9187 - val_loss: 0.2407 - val_acc: 0.9044\n",
      "Epoch 82/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.2004 - acc: 0.9214 - val_loss: 0.2122 - val_acc: 0.9159\n",
      "Epoch 83/120\n",
      "40900/40900 [==============================] - 128s 3ms/step - loss: 0.2085 - acc: 0.9180 - val_loss: 0.2039 - val_acc: 0.9195\n",
      "Epoch 84/120\n",
      "40900/40900 [==============================] - 130s 3ms/step - loss: 0.1980 - acc: 0.9216 - val_loss: 0.2781 - val_acc: 0.8782\n",
      "Epoch 85/120\n",
      "40900/40900 [==============================] - 131s 3ms/step - loss: 0.1898 - acc: 0.9261 - val_loss: 0.2437 - val_acc: 0.8997\n",
      "Epoch 86/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.1982 - acc: 0.9223 - val_loss: 0.2266 - val_acc: 0.9082\n",
      "Epoch 87/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.1945 - acc: 0.9252 - val_loss: 0.2136 - val_acc: 0.9138\n",
      "Epoch 88/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.1936 - acc: 0.9249 - val_loss: 0.2640 - val_acc: 0.9001\n",
      "Epoch 89/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.1969 - acc: 0.9221 - val_loss: 0.2218 - val_acc: 0.9115\n",
      "Epoch 90/120\n",
      "40900/40900 [==============================] - 124s 3ms/step - loss: 0.1861 - acc: 0.9272 - val_loss: 0.2445 - val_acc: 0.8979\n",
      "Epoch 91/120\n",
      "40900/40900 [==============================] - 125s 3ms/step - loss: 0.1891 - acc: 0.9260 - val_loss: 0.2710 - val_acc: 0.8914\n",
      "Epoch 92/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.1873 - acc: 0.9274 - val_loss: 0.3328 - val_acc: 0.8596\n",
      "Epoch 93/120\n",
      "40900/40900 [==============================] - 125s 3ms/step - loss: 0.1838 - acc: 0.9278 - val_loss: 0.2627 - val_acc: 0.8895\n",
      "Epoch 94/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.1950 - acc: 0.9245 - val_loss: 0.2764 - val_acc: 0.8885\n",
      "Epoch 95/120\n",
      "40900/40900 [==============================] - 129s 3ms/step - loss: 0.1792 - acc: 0.9300 - val_loss: 0.4628 - val_acc: 0.8344\n",
      "Epoch 96/120\n",
      "40900/40900 [==============================] - 130s 3ms/step - loss: 0.1842 - acc: 0.9278 - val_loss: 0.2282 - val_acc: 0.9047\n",
      "Epoch 97/120\n",
      "40900/40900 [==============================] - 132s 3ms/step - loss: 0.1823 - acc: 0.9279 - val_loss: 0.2274 - val_acc: 0.9075\n",
      "Epoch 98/120\n",
      "40900/40900 [==============================] - 131s 3ms/step - loss: 0.2790 - acc: 0.9027 - val_loss: 0.6106 - val_acc: 0.7435\n",
      "Epoch 99/120\n",
      "40900/40900 [==============================] - 136s 3ms/step - loss: 0.2305 - acc: 0.9088 - val_loss: 0.2142 - val_acc: 0.9150\n",
      "Epoch 100/120\n",
      "40900/40900 [==============================] - 131s 3ms/step - loss: 0.1790 - acc: 0.9301 - val_loss: 0.2194 - val_acc: 0.9122\n",
      "Epoch 101/120\n",
      "40900/40900 [==============================] - 128s 3ms/step - loss: 0.1846 - acc: 0.9284 - val_loss: 0.4286 - val_acc: 0.8476\n",
      "Epoch 102/120\n",
      "40900/40900 [==============================] - 147s 4ms/step - loss: 0.1831 - acc: 0.9291 - val_loss: 0.2104 - val_acc: 0.9139\n",
      "Epoch 103/120\n",
      "40900/40900 [==============================] - 132s 3ms/step - loss: 0.1736 - acc: 0.9310 - val_loss: 0.1996 - val_acc: 0.9217\n",
      "Epoch 104/120\n",
      "40900/40900 [==============================] - 123s 3ms/step - loss: 0.1767 - acc: 0.9305 - val_loss: 0.2173 - val_acc: 0.9143\n",
      "Epoch 105/120\n",
      "40900/40900 [==============================] - 128s 3ms/step - loss: 0.1693 - acc: 0.9343 - val_loss: 0.2941 - val_acc: 0.8856\n",
      "Epoch 106/120\n",
      "40900/40900 [==============================] - 131s 3ms/step - loss: 0.1690 - acc: 0.9349 - val_loss: 0.2174 - val_acc: 0.9124\n",
      "Epoch 107/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.1732 - acc: 0.9326 - val_loss: 0.2683 - val_acc: 0.8910\n",
      "Epoch 108/120\n",
      "40900/40900 [==============================] - 124s 3ms/step - loss: 0.1812 - acc: 0.9305 - val_loss: 0.2203 - val_acc: 0.9131\n",
      "Epoch 109/120\n",
      "40900/40900 [==============================] - 126s 3ms/step - loss: 0.1648 - acc: 0.9352 - val_loss: 0.1944 - val_acc: 0.9195\n",
      "Epoch 110/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.1688 - acc: 0.9354 - val_loss: 0.1895 - val_acc: 0.9235\n",
      "Epoch 111/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.1811 - acc: 0.9300 - val_loss: 0.2143 - val_acc: 0.9123\n",
      "Epoch 112/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.1670 - acc: 0.9350 - val_loss: 0.1953 - val_acc: 0.9220\n",
      "Epoch 113/120\n",
      "40900/40900 [==============================] - 127s 3ms/step - loss: 0.1602 - acc: 0.9370 - val_loss: 0.2066 - val_acc: 0.9148\n",
      "Epoch 114/120\n",
      "40900/40900 [==============================] - 124s 3ms/step - loss: 0.1681 - acc: 0.9339 - val_loss: 0.1989 - val_acc: 0.9215\n",
      "Epoch 115/120\n",
      "40900/40900 [==============================] - 124s 3ms/step - loss: 0.1588 - acc: 0.9374 - val_loss: 0.1910 - val_acc: 0.9239\n",
      "Epoch 116/120\n",
      "40900/40900 [==============================] - 124s 3ms/step - loss: 0.1580 - acc: 0.9385 - val_loss: 0.2010 - val_acc: 0.9206\n",
      "Epoch 117/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40900/40900 [==============================] - 124s 3ms/step - loss: 0.1571 - acc: 0.9394 - val_loss: 0.2241 - val_acc: 0.9095\n",
      "Epoch 118/120\n",
      "40900/40900 [==============================] - 123s 3ms/step - loss: 0.1575 - acc: 0.9376 - val_loss: 0.2927 - val_acc: 0.8777\n",
      "Epoch 119/120\n",
      "40900/40900 [==============================] - 122s 3ms/step - loss: 0.1667 - acc: 0.9363 - val_loss: 0.1760 - val_acc: 0.9307\n",
      "Epoch 120/120\n",
      "40900/40900 [==============================] - 124s 3ms/step - loss: 0.1897 - acc: 0.9277 - val_loss: 0.2037 - val_acc: 0.9203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a484775278>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.acc=[]\n",
    "    \n",
    "    def on_epoch_end(self,batch,logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "epochs = 120\n",
    "\n",
    "history=AccuracyHistory()\n",
    "        \n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         verbose=1,\n",
    "         validation_data=(x_test,y_test),\n",
    "         callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save(\"./New_defect_CNN.h5\")\n",
    "model.save_weights(\"./New_defect_CNN_weights.h5\")\n",
    "\n",
    "\n",
    "\"\"\"Or use this to save model\"\"\"\n",
    "\n",
    "#model_json = model.to_json()\n",
    "#with open(\"SJ_model.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "### serialize weights to HDF5\n",
    "#model.save_weights(\"SJ_model.h5\")\n",
    "\n",
    "print(\"Saved model and weights to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 60, 60, 16)        416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 26, 26, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 9, 9, 64)          51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 64,902\n",
      "Trainable params: 64,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Activation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining functions to use later ---\n",
    "\n",
    "def image_preprocessing_cam(image_data, image_size):\n",
    "    image_data = image_data.reshape(1, image_size[0], image_size[1], 1)\n",
    "    image_data = image_data.astype('float32')\n",
    "    image_data = (image_data - np.amin(image_data))/(np.amax(image_data) - np.amin(image_data))\n",
    "    return image_data\n",
    "\n",
    "def get_predictions(model, inputs):\n",
    "    return model.predict(inputs)\n",
    "\n",
    "def get_activation_maps(model, inputs, layer_num, learning_phase=0):\n",
    "    get_layer_output = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer_num].output])\n",
    "    layer_out = get_layer_output([inputs, learning_phase])[0]\n",
    "    layer_out = layer_out[0, :, :, :]\n",
    "    layer_out = np.transpose(layer_out,(2, 0, 1))\n",
    "    return layer_out\n",
    "\n",
    "def get_SoftmaxWeights(model):\n",
    "    return model.layers[-1].get_weights()[0]\n",
    "\n",
    "\"\"\"Load CNN Model here\"\"\"\n",
    "model = load_model('New_defect_CNN.h5')\n",
    "\n",
    "#model = model\n",
    "\n",
    "#no. of the last conv layer(can be found in model.summary() )\n",
    "last_conv_layer = -4\n",
    "\n",
    "image_size = 64, 64\n",
    "\n",
    "\"\"\"Load image file name here\"\"\"\n",
    "image_file = 'Vw_noisy'\n",
    "\n",
    "## Still working on this - incorporating coordinate search & making it better and well documented \n",
    "## but feel free to optimize\n",
    "img = cv2.imread(image_file + '.png', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, image_size, interpolation = cv2.INTER_AREA)\n",
    "img = image_preprocessing_cam(img, image_size) \n",
    "predictions = get_predictions(model, img)\n",
    "target_class = predictions.argmax()\n",
    "softmax_weights = get_SoftmaxWeights(model)\n",
    "conv_out = get_activation_maps(model, img, last_conv_layer)\n",
    "\n",
    "cam = np.zeros(shape = conv_out.shape[1:3], dtype = np.float32)\n",
    "\n",
    "for idx, weight in enumerate(softmax_weights[:, target_class]):\n",
    "    cam += weight * conv_out[idx, :, :]\n",
    "\n",
    "cam = (cam - np.amin(cam))/(np.amax(cam) - np.amin(cam))\n",
    "cam[np.where(cam < 0.2)] = 0\n",
    "cam = cv2.resize(cam, image_size)\n",
    "\n",
    "#max_coord = blob_log(cam, min_sigma=0.5)\n",
    "#x, y = np.transpose(max_coord)[0:2,:]\n",
    "#coordinates = list(zip(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Class activation map with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Original image + CAM ')"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a486bac9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread(image_file + '.png', cv2.IMREAD_GRAYSCALE)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(img, cmap = 'gray')\n",
    "ax1.set_title('Original image')\n",
    "ax2.imshow(cam, cmap = 'hot')\n",
    "ax2.imshow(img, cmap = 'gray', alpha = 0.5)\n",
    "ax2.set_title('Original image + CAM ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other stuff that I was trying - gradient class activation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-9da5a1c09d53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[0mpredicted_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m \u001b[0mcam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheatmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessed_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"conv2d_36\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gradcam.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-172-9da5a1c09d53>\u001b[0m in \u001b[0;36mgrad_cam\u001b[1;34m(input_model, image, category_index, layer_name)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0mconv_output\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mgradient_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.framework import ops\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "def target_category_loss(x, category_index, nb_classes):\n",
    "    return tf.multiply(x, K.one_hot([category_index], nb_classes))\n",
    "\n",
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "\n",
    "def load_image(img_path):\n",
    "    \n",
    "    img = image.load_img(img_path, grayscale = True, target_size=(64, 64))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "def register_gradient():\n",
    "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
    "        @ops.RegisterGradient(\"GuidedBackProp\")\n",
    "        def _GuidedBackProp(op, grad):\n",
    "            dtype = op.inputs[0].dtype\n",
    "            return grad * tf.cast(grad > 0., dtype) * \\\n",
    "                tf.cast(op.inputs[0] > 0., dtype)\n",
    "\n",
    "def compile_saliency_function(model, activation_layer=\"conv2d_2\"):\n",
    "    input_img = model.input\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    layer_output = layer_dict[activation_layer].output\n",
    "    max_output = K.max(layer_output, axis=3)\n",
    "    saliency = K.gradients(K.sum(max_output), input_img)[0]\n",
    "    return K.function([input_img, K.learning_phase()], [saliency])\n",
    "\n",
    "def modify_backprop(model, name):\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({'Relu': name}):\n",
    "\n",
    "        # get layers that have an activation\n",
    "        layer_dict = [layer for layer in model.layers[1:]\n",
    "                      if hasattr(layer, 'activation')]\n",
    "\n",
    "        # replace relu activation\n",
    "        for layer in layer_dict:\n",
    "            if layer.activation == keras.activations.relu:\n",
    "                layer.activation = tf.nn.relu\n",
    "\n",
    "        # re-instanciate a new model\n",
    "        new_model = VGG16(weights='imagenet') ##########################################################\n",
    "    return new_model\n",
    "\n",
    "def deprocess_image(x):\n",
    "    '''\n",
    "    Same normalization as in:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "    '''\n",
    "    if np.ndim(x) > 3:\n",
    "        x = np.squeeze(x)\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def grad_cam(input_model, image, category_index, layer_name):\n",
    "    model = Sequential()\n",
    "    model.add(input_model)\n",
    "\n",
    "    nb_classes = 6\n",
    "    target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "    model.add(Lambda(target_layer,\n",
    "                     output_shape = target_category_loss_output_shape))\n",
    "\n",
    "    loss = K.sum(model.layers[-1].output)\n",
    "    conv_output =  [l for l in model.layers[0].layers if l.name is layer_name][0].output\n",
    "    grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "    gradient_function = K.function([model.layers[0].input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis = (0, 1))\n",
    "    cam = np.ones(output.shape[0 : 2], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, :, i]\n",
    "\n",
    "    cam = cv2.resize(cam, (64, 64))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "\n",
    "    #Return to BGR [0..255] from the preprocessed image\n",
    "    image = image[0, :]\n",
    "    image -= np.min(image)\n",
    "    image = np.minimum(image, 255)\n",
    "\n",
    "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "    cam = np.float32(cam) + np.float32(image)\n",
    "    cam = 255 * cam / np.max(cam)\n",
    "    return np.uint8(cam), heatmap\n",
    "\n",
    "preprocessed_input = load_image('SJ.png')\n",
    "\n",
    "model = model\n",
    "\n",
    "predictions = model.predict(preprocessed_input)\n",
    "#top_1 = decode_predictions(predictions)[0][0]\n",
    "#print('Predicted class:')\n",
    "#print('%s (%s) with probability %.2f' % (top_1[1], top_1[0], top_1[2]))\n",
    "\n",
    "predicted_class = np.argmax(predictions)\n",
    "cam, heatmap = grad_cam(model, preprocessed_input, predicted_class, \"conv2d_36\")\n",
    "cv2.imwrite(\"gradcam.jpg\", cam)\n",
    "\n",
    "#register_gradient()\n",
    "#guided_model = modify_backprop(model, 'GuidedBackProp')\n",
    "#saliency_fn = compile_saliency_function(guided_model)\n",
    "#saliency = saliency_fn([preprocessed_input, 0])\n",
    "#gradcam = saliency[0] * heatmap[..., np.newaxis]\n",
    "#cv2.imwrite(\"guided_gradcam.jpg\", deprocess_image(gradcam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "model_path = model \n",
    "img_path = \"SJ.png\"\n",
    "output_path = \"Trail_Image.png\"\n",
    "\n",
    "def visualize_class_activation_map(model_path, img_path, output_path):\n",
    "        model = load_model(model_path)\n",
    "        original_img = cv2.imread(img_path, 1)\n",
    "        width, height, _ = original_img.shape\n",
    "\n",
    "        #Reshape to the network input shape (3, w, h).\n",
    "        img = np.array([np.transpose(np.float32(original_img), (2, 0, 1))])\n",
    "        \n",
    "        #Get the 512 input weights to the softmax.\n",
    "        class_weights = model.layers[-1].get_weights()[0]\n",
    "        final_conv_layer = model.get_layer(\"conv2d_36\")\n",
    "        #final_conv_layer = get_output_layer(model, \"conv5_3\")\n",
    "        get_output = K.function([model.layers[0].input], [final_conv_layer.output, model.layers[-1].output])\n",
    "        [conv_outputs, predictions] = get_output([img])\n",
    "        conv_outputs = conv_outputs[0, :, :, :]\n",
    "\n",
    "        #Create the class activation map.\n",
    "        cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])\n",
    "        for i, w in enumerate(class_weights[:, 1]):\n",
    "                cam += w * conv_outputs[i, :, :]\n",
    "        \n",
    "        cam /= np.max(cam)\n",
    "        cam = cv2.resize(cam, (height, width))\n",
    "        heatmap = cv2.applyColorMap(np.uint8(cam), cv2.COLORMAP_JET)\n",
    "        heatmap[np.where(cam < 0.2)] = 0\n",
    "        img = heatmap*0.5 + original_img\n",
    "        cv2.imwrite(output_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "##### add layers to CNN model: \n",
    "model.add(Conv2D(32,kernel_size=(5,5),strides=(1,1),\n",
    "                activation='relu',\n",
    "                input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(64,(5,5),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000,activation='relu'))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "######\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40900 samples, validate on 10225 samples\n",
      "Epoch 1/50\n",
      "40900/40900 [==============================] - 283s 7ms/step - loss: 1.6054 - acc: 0.3772 - val_loss: 1.2119 - val_acc: 0.5668\n",
      "Epoch 2/50\n",
      "40900/40900 [==============================] - 279s 7ms/step - loss: 0.8499 - acc: 0.6784 - val_loss: 0.6669 - val_acc: 0.7566\n",
      "Epoch 3/50\n",
      "40900/40900 [==============================] - 273s 7ms/step - loss: 0.4930 - acc: 0.8068 - val_loss: 0.4115 - val_acc: 0.8365\n",
      "Epoch 4/50\n",
      "40900/40900 [==============================] - 271s 7ms/step - loss: 0.3457 - acc: 0.8667 - val_loss: 0.3731 - val_acc: 0.8498\n",
      "Epoch 5/50\n",
      "40900/40900 [==============================] - 273s 7ms/step - loss: 0.2912 - acc: 0.8860 - val_loss: 0.2777 - val_acc: 0.8920\n",
      "Epoch 6/50\n",
      "40900/40900 [==============================] - 273s 7ms/step - loss: 0.2624 - acc: 0.9003 - val_loss: 0.2308 - val_acc: 0.9099\n",
      "Epoch 7/50\n",
      "40900/40900 [==============================] - 272s 7ms/step - loss: 0.2321 - acc: 0.9101 - val_loss: 0.2453 - val_acc: 0.8965\n",
      "Epoch 8/50\n",
      "40900/40900 [==============================] - 270s 7ms/step - loss: 0.2138 - acc: 0.9176 - val_loss: 0.2147 - val_acc: 0.9176\n",
      "Epoch 9/50\n",
      "40900/40900 [==============================] - 268s 7ms/step - loss: 0.1913 - acc: 0.9276 - val_loss: 0.1988 - val_acc: 0.9217\n",
      "Epoch 10/50\n",
      "40900/40900 [==============================] - 22622s 553ms/step - loss: 0.1830 - acc: 0.9299 - val_loss: 0.1974 - val_acc: 0.9239\n",
      "Epoch 11/50\n",
      "40900/40900 [==============================] - 277s 7ms/step - loss: 0.1912 - acc: 0.9286 - val_loss: 0.4051 - val_acc: 0.8303\n",
      "Epoch 12/50\n",
      "40900/40900 [==============================] - 277s 7ms/step - loss: 0.1718 - acc: 0.9356 - val_loss: 0.1793 - val_acc: 0.9273\n",
      "Epoch 13/50\n",
      "40900/40900 [==============================] - 22084s 540ms/step - loss: 0.1580 - acc: 0.9424 - val_loss: 0.1753 - val_acc: 0.9293\n",
      "Epoch 14/50\n",
      "40900/40900 [==============================] - 1905s 47ms/step - loss: 0.1454 - acc: 0.9472 - val_loss: 0.1562 - val_acc: 0.9371\n",
      "Epoch 15/50\n",
      "40900/40900 [==============================] - 313s 8ms/step - loss: 0.1261 - acc: 0.9550 - val_loss: 0.1503 - val_acc: 0.9373\n",
      "Epoch 16/50\n",
      "40900/40900 [==============================] - 285s 7ms/step - loss: 0.1221 - acc: 0.9562 - val_loss: 0.1580 - val_acc: 0.9350\n",
      "Epoch 17/50\n",
      "40900/40900 [==============================] - 280s 7ms/step - loss: 0.1136 - acc: 0.9594 - val_loss: 0.2330 - val_acc: 0.9061\n",
      "Epoch 18/50\n",
      "40900/40900 [==============================] - 280s 7ms/step - loss: 0.1089 - acc: 0.9613 - val_loss: 0.1277 - val_acc: 0.9487\n",
      "Epoch 19/50\n",
      "40900/40900 [==============================] - 269s 7ms/step - loss: 0.0974 - acc: 0.9659 - val_loss: 0.1457 - val_acc: 0.9420\n",
      "Epoch 20/50\n",
      "40900/40900 [==============================] - 263s 6ms/step - loss: 0.1009 - acc: 0.9653 - val_loss: 0.1632 - val_acc: 0.9402\n",
      "Epoch 21/50\n",
      "40900/40900 [==============================] - 264s 6ms/step - loss: 0.0917 - acc: 0.9689 - val_loss: 0.1264 - val_acc: 0.9512\n",
      "Epoch 22/50\n",
      "40900/40900 [==============================] - 266s 6ms/step - loss: 0.0905 - acc: 0.9704 - val_loss: 0.1181 - val_acc: 0.9543\n",
      "Epoch 23/50\n",
      "40900/40900 [==============================] - 3070s 75ms/step - loss: 0.0785 - acc: 0.9737 - val_loss: 0.1269 - val_acc: 0.9495\n",
      "Epoch 24/50\n",
      "40900/40900 [==============================] - 3663s 90ms/step - loss: 0.0856 - acc: 0.9708 - val_loss: 0.1372 - val_acc: 0.9476\n",
      "Epoch 25/50\n",
      "40900/40900 [==============================] - 387s 9ms/step - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1240 - val_acc: 0.9489\n",
      "Epoch 26/50\n",
      "40900/40900 [==============================] - 299s 7ms/step - loss: 0.0700 - acc: 0.9781 - val_loss: 0.1186 - val_acc: 0.9538\n",
      "Epoch 27/50\n",
      "40900/40900 [==============================] - 288s 7ms/step - loss: 0.0640 - acc: 0.9787 - val_loss: 0.1139 - val_acc: 0.9563\n",
      "Epoch 28/50\n",
      "40900/40900 [==============================] - 283s 7ms/step - loss: 0.0619 - acc: 0.9799 - val_loss: 0.1058 - val_acc: 0.9582\n",
      "Epoch 29/50\n",
      "40900/40900 [==============================] - 288s 7ms/step - loss: 0.0628 - acc: 0.9802 - val_loss: 0.1207 - val_acc: 0.9544\n",
      "Epoch 30/50\n",
      "40900/40900 [==============================] - 284s 7ms/step - loss: 0.0523 - acc: 0.9839 - val_loss: 0.0960 - val_acc: 0.9632\n",
      "Epoch 31/50\n",
      "40900/40900 [==============================] - 282s 7ms/step - loss: 0.0522 - acc: 0.9839 - val_loss: 0.0983 - val_acc: 0.9615\n",
      "Epoch 32/50\n",
      "40900/40900 [==============================] - 276s 7ms/step - loss: 0.0465 - acc: 0.9856 - val_loss: 0.0948 - val_acc: 0.9637\n",
      "Epoch 33/50\n",
      "40900/40900 [==============================] - 280s 7ms/step - loss: 0.0451 - acc: 0.9865 - val_loss: 0.1065 - val_acc: 0.9596\n",
      "Epoch 34/50\n",
      "40900/40900 [==============================] - 286s 7ms/step - loss: 0.0824 - acc: 0.9784 - val_loss: 0.1257 - val_acc: 0.9515\n",
      "Epoch 35/50\n",
      "40900/40900 [==============================] - 288s 7ms/step - loss: 0.0630 - acc: 0.9801 - val_loss: 0.1274 - val_acc: 0.9520\n",
      "Epoch 36/50\n",
      "40900/40900 [==============================] - 295s 7ms/step - loss: 0.0509 - acc: 0.9847 - val_loss: 0.1019 - val_acc: 0.9604\n",
      "Epoch 37/50\n",
      "40900/40900 [==============================] - 277s 7ms/step - loss: 0.0412 - acc: 0.9877 - val_loss: 0.0925 - val_acc: 0.9642\n",
      "Epoch 38/50\n",
      "40900/40900 [==============================] - 277s 7ms/step - loss: 0.0762 - acc: 0.9784 - val_loss: 0.0985 - val_acc: 0.9638\n",
      "Epoch 39/50\n",
      "40900/40900 [==============================] - 281s 7ms/step - loss: 0.0399 - acc: 0.9880 - val_loss: 0.1156 - val_acc: 0.9566\n",
      "Epoch 40/50\n",
      "40900/40900 [==============================] - 278s 7ms/step - loss: 0.0377 - acc: 0.9883 - val_loss: 0.0927 - val_acc: 0.9649\n",
      "Epoch 41/50\n",
      "40900/40900 [==============================] - 273s 7ms/step - loss: 0.0514 - acc: 0.9862 - val_loss: 0.1502 - val_acc: 0.9464\n",
      "Epoch 42/50\n",
      "40900/40900 [==============================] - 267s 7ms/step - loss: 0.0516 - acc: 0.9843 - val_loss: 0.1164 - val_acc: 0.9583\n",
      "Epoch 43/50\n",
      "40900/40900 [==============================] - 265s 6ms/step - loss: 0.0436 - acc: 0.9869 - val_loss: 0.1041 - val_acc: 0.9620\n",
      "Epoch 44/50\n",
      "40900/40900 [==============================] - 270s 7ms/step - loss: 0.0366 - acc: 0.9891 - val_loss: 0.1010 - val_acc: 0.9610\n",
      "Epoch 45/50\n",
      "40900/40900 [==============================] - 280s 7ms/step - loss: 0.0339 - acc: 0.9903 - val_loss: 0.1123 - val_acc: 0.9606\n",
      "Epoch 46/50\n",
      "40900/40900 [==============================] - 279s 7ms/step - loss: 0.0323 - acc: 0.9906 - val_loss: 0.1145 - val_acc: 0.9576\n",
      "Epoch 47/50\n",
      "40900/40900 [==============================] - 276s 7ms/step - loss: 0.0308 - acc: 0.9911 - val_loss: 0.1021 - val_acc: 0.9620\n",
      "Epoch 48/50\n",
      "40900/40900 [==============================] - 268s 7ms/step - loss: 0.0289 - acc: 0.9915 - val_loss: 0.1084 - val_acc: 0.9604\n",
      "Epoch 49/50\n",
      "40900/40900 [==============================] - 269s 7ms/step - loss: 0.0278 - acc: 0.9921 - val_loss: 0.0943 - val_acc: 0.9652\n",
      "Epoch 50/50\n",
      "40900/40900 [==============================] - 271s 7ms/step - loss: 0.0270 - acc: 0.9920 - val_loss: 0.1086 - val_acc: 0.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb306e9c88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.acc=[]\n",
    "    \n",
    "    def on_epoch_end(self,batch,logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history=AccuracyHistory()\n",
    "        \n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         verbose=1,\n",
    "         validation_data=(x_test,y_test),\n",
    "         callbacks=[history])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
