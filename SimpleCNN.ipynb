{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build train and test data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import blob_log\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read in all the augmented and noisy images\n",
    "path = \"./Multislice\"\n",
    "folders=os.listdir(path) \n",
    "data=[]    #all the images will be stored in this list.\n",
    "defecttype=[]    #all the defect type corresponding to each image store in this list\n",
    "defects={'Sw':0,'Mo':1,'W2s2':2,'Vw':3,'Vs2':4,'Ws':5}     # each int represents a defect type\n",
    "\n",
    "for folder in folders:  #traversing all subfolders(types of defects) in MULTISLICE\n",
    "    if '.' in folder:   #make sure it will not traverse file like '.DS_store'\n",
    "        continue\n",
    "    \n",
    "    noisy_path = \"./Multislice\"+\"/\"+folder+'/'+folder+'_Augmented' \n",
    "    filelist = glob.glob(noisy_path+'/*.png')\n",
    "    data.extend([img_to_array(load_img(fname, grayscale = True)) for fname in filelist])\n",
    "    defecttype.extend([defects[folder]]*len(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51125, 64, 64, 1)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## there should be 51125 images, each image with size of (64,64,1)\n",
    "np.array(data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "\n",
    "### We might want to try Suffle split to reduce bias in the test train split \n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(data), defecttype, test_size = 0.2, random_state = 28956)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 6\n",
    "#epochs = 50\n",
    "\n",
    "# input image dimensions\n",
    "img_x, img_y = 64, 64\n",
    "input_shape = (img_x, img_y, 1)\n",
    "\n",
    "# Normalizing data\n",
    "x_train = (x_train - np.amin(x_train))/(np.amax(x_train) - np.amin(x_train))\n",
    "x_test = (x_test - np.amin(x_test))/(np.amax(x_test) - np.amin(x_test))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "##### add layers to CNN model: \n",
    "model.add(Conv2D(16,kernel_size=(6,6),strides=(1,1),activation='relu',input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "#model.add(Conv2D(16,(5,5),activation='relu'))\n",
    "#model.add(Conv2D(16,(3,3),activation='relu'))\n",
    "#model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(6,6),activation='relu'))\n",
    "#model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(6,6),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "######\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "##### add layers to CNN model: \n",
    "model.add(Conv2D(8,kernel_size=(7,7),strides=(1,1),activation='relu',input_shape=input_shape))\n",
    "#model.add(Conv2D(8,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(16,(5,5),activation='relu'))\n",
    "#model.add(Conv2D(16,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "#model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "######\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40900 samples, validate on 10225 samples\n",
      "Epoch 1/120\n",
      "40900/40900 [==============================] - 92s 2ms/step - loss: 1.7701 - acc: 0.2738 - val_loss: 1.7436 - val_acc: 0.2696\n",
      "Epoch 2/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 1.5735 - acc: 0.3572 - val_loss: 1.4820 - val_acc: 0.3301\n",
      "Epoch 3/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.9891 - acc: 0.5759 - val_loss: 0.7066 - val_acc: 0.7069\n",
      "Epoch 4/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.6663 - acc: 0.7127 - val_loss: 0.5749 - val_acc: 0.7408\n",
      "Epoch 5/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.5448 - acc: 0.7733 - val_loss: 0.5570 - val_acc: 0.8001\n",
      "Epoch 6/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.4717 - acc: 0.8067 - val_loss: 0.4838 - val_acc: 0.8185\n",
      "Epoch 7/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.4132 - acc: 0.8338 - val_loss: 0.3685 - val_acc: 0.8548\n",
      "Epoch 8/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.3752 - acc: 0.8489 - val_loss: 0.3500 - val_acc: 0.8561\n",
      "Epoch 9/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.3417 - acc: 0.8634 - val_loss: 0.3471 - val_acc: 0.8737\n",
      "Epoch 10/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.3190 - acc: 0.8733 - val_loss: 0.3096 - val_acc: 0.8724\n",
      "Epoch 11/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.3021 - acc: 0.8814 - val_loss: 0.3210 - val_acc: 0.8735\n",
      "Epoch 12/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.2846 - acc: 0.8867 - val_loss: 0.2872 - val_acc: 0.8885\n",
      "Epoch 13/120\n",
      "40900/40900 [==============================] - 93s 2ms/step - loss: 0.2689 - acc: 0.8937 - val_loss: 0.2875 - val_acc: 0.8881\n",
      "Epoch 14/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.2544 - acc: 0.8980 - val_loss: 0.2927 - val_acc: 0.8816\n",
      "Epoch 15/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.2452 - acc: 0.9022 - val_loss: 0.2871 - val_acc: 0.8828\n",
      "Epoch 16/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.2358 - acc: 0.9064 - val_loss: 0.2453 - val_acc: 0.9013\n",
      "Epoch 17/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.2252 - acc: 0.9111 - val_loss: 0.2291 - val_acc: 0.9102\n",
      "Epoch 18/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.2158 - acc: 0.9157 - val_loss: 0.2255 - val_acc: 0.9103\n",
      "Epoch 19/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.2090 - acc: 0.9180 - val_loss: 0.2415 - val_acc: 0.9019\n",
      "Epoch 20/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.2035 - acc: 0.9203 - val_loss: 0.2117 - val_acc: 0.9168\n",
      "Epoch 21/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1936 - acc: 0.9240 - val_loss: 0.2343 - val_acc: 0.9067\n",
      "Epoch 22/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1948 - acc: 0.9228 - val_loss: 0.1971 - val_acc: 0.9216\n",
      "Epoch 23/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1855 - acc: 0.9285 - val_loss: 0.2614 - val_acc: 0.8974\n",
      "Epoch 24/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1776 - acc: 0.9307 - val_loss: 0.1964 - val_acc: 0.9243\n",
      "Epoch 25/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1705 - acc: 0.9342 - val_loss: 0.2112 - val_acc: 0.9162\n",
      "Epoch 26/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1644 - acc: 0.9360 - val_loss: 0.1988 - val_acc: 0.9220\n",
      "Epoch 27/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1610 - acc: 0.9384 - val_loss: 0.3001 - val_acc: 0.8768\n",
      "Epoch 28/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1592 - acc: 0.9382 - val_loss: 0.1823 - val_acc: 0.9283\n",
      "Epoch 29/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1545 - acc: 0.9414 - val_loss: 0.1742 - val_acc: 0.9353\n",
      "Epoch 30/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1466 - acc: 0.9448 - val_loss: 0.1706 - val_acc: 0.9349\n",
      "Epoch 31/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1462 - acc: 0.9444 - val_loss: 0.2062 - val_acc: 0.9183\n",
      "Epoch 32/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.1426 - acc: 0.9455 - val_loss: 0.1943 - val_acc: 0.9290\n",
      "Epoch 33/120\n",
      "40900/40900 [==============================] - 92s 2ms/step - loss: 0.1332 - acc: 0.9495 - val_loss: 0.2016 - val_acc: 0.9186\n",
      "Epoch 34/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1333 - acc: 0.9489 - val_loss: 0.1785 - val_acc: 0.9339\n",
      "Epoch 35/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1298 - acc: 0.9507 - val_loss: 0.1680 - val_acc: 0.9355\n",
      "Epoch 36/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1275 - acc: 0.9530 - val_loss: 0.1828 - val_acc: 0.9310\n",
      "Epoch 37/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1267 - acc: 0.9524 - val_loss: 0.1612 - val_acc: 0.9384\n",
      "Epoch 38/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1258 - acc: 0.9519 - val_loss: 0.1630 - val_acc: 0.9371\n",
      "Epoch 39/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1169 - acc: 0.9566 - val_loss: 0.1704 - val_acc: 0.9343\n",
      "Epoch 40/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1179 - acc: 0.9554 - val_loss: 0.1733 - val_acc: 0.9344\n",
      "Epoch 41/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1128 - acc: 0.9571 - val_loss: 0.1544 - val_acc: 0.9443\n",
      "Epoch 42/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1094 - acc: 0.9589 - val_loss: 0.1519 - val_acc: 0.9453\n",
      "Epoch 43/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1105 - acc: 0.9587 - val_loss: 0.1777 - val_acc: 0.9342\n",
      "Epoch 44/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1067 - acc: 0.9602 - val_loss: 0.1802 - val_acc: 0.9309\n",
      "Epoch 45/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.1032 - acc: 0.9616 - val_loss: 0.1736 - val_acc: 0.9322\n",
      "Epoch 46/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.1014 - acc: 0.9625 - val_loss: 0.1517 - val_acc: 0.9443\n",
      "Epoch 47/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0957 - acc: 0.9651 - val_loss: 0.1499 - val_acc: 0.9464\n",
      "Epoch 48/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0981 - acc: 0.9641 - val_loss: 0.1505 - val_acc: 0.9461\n",
      "Epoch 49/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0942 - acc: 0.9649 - val_loss: 0.1544 - val_acc: 0.9447\n",
      "Epoch 50/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0948 - acc: 0.9651 - val_loss: 0.1839 - val_acc: 0.9337\n",
      "Epoch 51/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0920 - acc: 0.9656 - val_loss: 0.1501 - val_acc: 0.9480\n",
      "Epoch 52/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0891 - acc: 0.9671 - val_loss: 0.1366 - val_acc: 0.9517\n",
      "Epoch 53/120\n",
      "40900/40900 [==============================] - 92s 2ms/step - loss: 0.0913 - acc: 0.9668 - val_loss: 0.1654 - val_acc: 0.9416\n",
      "Epoch 54/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0826 - acc: 0.9697 - val_loss: 0.1826 - val_acc: 0.9396\n",
      "Epoch 55/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0831 - acc: 0.9691 - val_loss: 0.1389 - val_acc: 0.9511\n",
      "Epoch 56/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0830 - acc: 0.9697 - val_loss: 0.1839 - val_acc: 0.9327\n",
      "Epoch 57/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0786 - acc: 0.9718 - val_loss: 0.1667 - val_acc: 0.9416\n",
      "Epoch 58/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0779 - acc: 0.9714 - val_loss: 0.1822 - val_acc: 0.9347\n",
      "Epoch 59/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0784 - acc: 0.9713 - val_loss: 0.2227 - val_acc: 0.9287\n",
      "Epoch 60/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.0753 - acc: 0.9731 - val_loss: 0.1676 - val_acc: 0.9427\n",
      "Epoch 61/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0760 - acc: 0.9724 - val_loss: 0.1369 - val_acc: 0.9528\n",
      "Epoch 62/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0714 - acc: 0.9743 - val_loss: 0.1405 - val_acc: 0.9524\n",
      "Epoch 63/120\n",
      "40900/40900 [==============================] - 94s 2ms/step - loss: 0.0706 - acc: 0.9751 - val_loss: 0.1428 - val_acc: 0.9516\n",
      "Epoch 64/120\n",
      "40900/40900 [==============================] - 92s 2ms/step - loss: 0.0732 - acc: 0.9738 - val_loss: 0.1512 - val_acc: 0.9493\n",
      "Epoch 65/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.0710 - acc: 0.9747 - val_loss: 0.1539 - val_acc: 0.9488\n",
      "Epoch 66/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.0662 - acc: 0.9765 - val_loss: 0.1761 - val_acc: 0.9422\n",
      "Epoch 67/120\n",
      "40900/40900 [==============================] - 94s 2ms/step - loss: 0.0637 - acc: 0.9774 - val_loss: 0.1461 - val_acc: 0.9528\n",
      "Epoch 68/120\n",
      "40900/40900 [==============================] - 93s 2ms/step - loss: 0.0647 - acc: 0.9769 - val_loss: 0.1589 - val_acc: 0.9467\n",
      "Epoch 69/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0702 - acc: 0.9762 - val_loss: 0.1886 - val_acc: 0.9386\n",
      "Epoch 70/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.0615 - acc: 0.9785 - val_loss: 0.1407 - val_acc: 0.9523\n",
      "Epoch 71/120\n",
      "40900/40900 [==============================] - 92s 2ms/step - loss: 0.0639 - acc: 0.9775 - val_loss: 0.1428 - val_acc: 0.9529\n",
      "Epoch 72/120\n",
      "40900/40900 [==============================] - 92s 2ms/step - loss: 0.0578 - acc: 0.9798 - val_loss: 0.1474 - val_acc: 0.9528\n",
      "Epoch 73/120\n",
      "40900/40900 [==============================] - 94s 2ms/step - loss: 0.0563 - acc: 0.9801 - val_loss: 0.1607 - val_acc: 0.9491\n",
      "Epoch 74/120\n",
      "40900/40900 [==============================] - 93s 2ms/step - loss: 0.0591 - acc: 0.9794 - val_loss: 0.1749 - val_acc: 0.9435\n",
      "Epoch 75/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0561 - acc: 0.9797 - val_loss: 0.1492 - val_acc: 0.9519\n",
      "Epoch 76/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0562 - acc: 0.9805 - val_loss: 0.2590 - val_acc: 0.9284\n",
      "Epoch 77/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0682 - acc: 0.9776 - val_loss: 0.1675 - val_acc: 0.9456\n",
      "Epoch 78/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0577 - acc: 0.9794 - val_loss: 0.2135 - val_acc: 0.9335\n",
      "Epoch 79/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0512 - acc: 0.9816 - val_loss: 0.1547 - val_acc: 0.9511\n",
      "Epoch 80/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0529 - acc: 0.9816 - val_loss: 0.1574 - val_acc: 0.9494\n",
      "Epoch 81/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.0467 - acc: 0.9843 - val_loss: 0.1884 - val_acc: 0.9430\n",
      "Epoch 82/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.0469 - acc: 0.9840 - val_loss: 0.1484 - val_acc: 0.9547\n",
      "Epoch 83/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0475 - acc: 0.9838 - val_loss: 0.1547 - val_acc: 0.9542\n",
      "Epoch 84/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.0434 - acc: 0.9852 - val_loss: 0.1759 - val_acc: 0.9462\n",
      "Epoch 85/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.0431 - acc: 0.9855 - val_loss: 0.1475 - val_acc: 0.9546\n",
      "Epoch 86/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.0485 - acc: 0.9842 - val_loss: 0.1667 - val_acc: 0.9490\n",
      "Epoch 87/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0538 - acc: 0.9827 - val_loss: 0.1460 - val_acc: 0.9544\n",
      "Epoch 88/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0412 - acc: 0.9856 - val_loss: 0.1824 - val_acc: 0.9456\n",
      "Epoch 89/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0384 - acc: 0.9876 - val_loss: 0.1504 - val_acc: 0.9543\n",
      "Epoch 90/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0437 - acc: 0.9861 - val_loss: 0.1712 - val_acc: 0.9515\n",
      "Epoch 91/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0428 - acc: 0.9857 - val_loss: 0.1486 - val_acc: 0.9540\n",
      "Epoch 92/120\n",
      "40900/40900 [==============================] - 91s 2ms/step - loss: 0.0373 - acc: 0.9880 - val_loss: 0.1546 - val_acc: 0.9543\n",
      "Epoch 93/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0375 - acc: 0.9877 - val_loss: 0.1564 - val_acc: 0.9547\n",
      "Epoch 94/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0439 - acc: 0.9868 - val_loss: 0.1504 - val_acc: 0.9551\n",
      "Epoch 95/120\n",
      "40900/40900 [==============================] - 93s 2ms/step - loss: 0.0459 - acc: 0.9851 - val_loss: 0.2884 - val_acc: 0.9290\n",
      "Epoch 96/120\n",
      "40900/40900 [==============================] - 97s 2ms/step - loss: 0.0365 - acc: 0.9879 - val_loss: 0.1523 - val_acc: 0.9563\n",
      "Epoch 97/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0456 - acc: 0.9870 - val_loss: 0.1539 - val_acc: 0.9525\n",
      "Epoch 98/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0338 - acc: 0.9891 - val_loss: 0.1525 - val_acc: 0.9576\n",
      "Epoch 99/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0618 - acc: 0.9822 - val_loss: 0.1532 - val_acc: 0.9559\n",
      "Epoch 100/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0366 - acc: 0.9884 - val_loss: 0.1525 - val_acc: 0.9559\n",
      "Epoch 101/120\n",
      "40900/40900 [==============================] - 90s 2ms/step - loss: 0.0310 - acc: 0.9896 - val_loss: 0.1623 - val_acc: 0.9546\n",
      "Epoch 102/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0325 - acc: 0.9893 - val_loss: 0.1726 - val_acc: 0.9526\n",
      "Epoch 103/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0317 - acc: 0.9897 - val_loss: 0.1600 - val_acc: 0.9526\n",
      "Epoch 104/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0392 - acc: 0.9891 - val_loss: 0.1638 - val_acc: 0.9533\n",
      "Epoch 105/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0292 - acc: 0.9907 - val_loss: 0.1645 - val_acc: 0.9550\n",
      "Epoch 106/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0600 - acc: 0.9833 - val_loss: 0.1830 - val_acc: 0.9495\n",
      "Epoch 107/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0312 - acc: 0.9905 - val_loss: 0.2051 - val_acc: 0.9414\n",
      "Epoch 108/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0291 - acc: 0.9912 - val_loss: 0.1643 - val_acc: 0.9553\n",
      "Epoch 109/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0287 - acc: 0.9905 - val_loss: 0.1610 - val_acc: 0.9545\n",
      "Epoch 110/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0279 - acc: 0.9909 - val_loss: 0.1646 - val_acc: 0.9550\n",
      "Epoch 111/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0241 - acc: 0.9926 - val_loss: 0.1663 - val_acc: 0.9551\n",
      "Epoch 112/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0233 - acc: 0.9931 - val_loss: 0.1694 - val_acc: 0.9543\n",
      "Epoch 113/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0545 - acc: 0.9870 - val_loss: 0.1719 - val_acc: 0.9529\n",
      "Epoch 114/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0285 - acc: 0.9909 - val_loss: 0.1713 - val_acc: 0.9553\n",
      "Epoch 115/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0229 - acc: 0.9931 - val_loss: 0.1659 - val_acc: 0.9569\n",
      "Epoch 116/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0398 - acc: 0.9905 - val_loss: 0.1708 - val_acc: 0.9553\n",
      "Epoch 117/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0282 - acc: 0.9923 - val_loss: 0.1824 - val_acc: 0.9530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0213 - acc: 0.9937 - val_loss: 0.1666 - val_acc: 0.9558\n",
      "Epoch 119/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0209 - acc: 0.9940 - val_loss: 0.1740 - val_acc: 0.9550\n",
      "Epoch 120/120\n",
      "40900/40900 [==============================] - 89s 2ms/step - loss: 0.0203 - acc: 0.9937 - val_loss: 0.1770 - val_acc: 0.9542\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a9247d4e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.acc=[]\n",
    "    \n",
    "    def on_epoch_end(self,batch,logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "epochs = 120\n",
    "\n",
    "history=AccuracyHistory()\n",
    "        \n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         verbose=1,\n",
    "         validation_data=(x_test,y_test),\n",
    "         callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and weights to disk\n"
     ]
    }
   ],
   "source": [
    "#save the model\n",
    "model.save(\"./New_5_8_18_defect_CNN.h5\")\n",
    "model.save_weights(\"./New_5_8_18_defect_CNN_weights.h5\")\n",
    "\n",
    "\n",
    "\"\"\"Or use this to save model\"\"\"\n",
    "\n",
    "#model_json = model.to_json()\n",
    "#with open(\"SJ_model.json\", \"w\") as json_file:\n",
    "#    json_file.write(model_json)\n",
    "### serialize weights to HDF5\n",
    "#model.save_weights(\"SJ_model.h5\")\n",
    "\n",
    "print(\"Saved model and weights to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 58, 58, 8)         400       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 29, 29, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 25, 25, 16)        3216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 10, 10, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 27,142\n",
      "Trainable params: 27,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Activation Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining functions to use later ---\n",
    "\n",
    "def image_preprocessing_cam(image_data, image_size):\n",
    "    image_data = image_data.reshape(1, image_size[0], image_size[1], 1)\n",
    "    image_data = image_data.astype('float32')\n",
    "    image_data = (image_data - np.amin(image_data))/(np.amax(image_data) - np.amin(image_data))\n",
    "    return image_data\n",
    "\n",
    "def get_predictions(model, inputs):\n",
    "    return model.predict(inputs)\n",
    "\n",
    "def get_activation_maps(model, inputs, layer_num, learning_phase=0):\n",
    "    get_layer_output = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer_num].output])\n",
    "    layer_out = get_layer_output([inputs, learning_phase])[0]\n",
    "    layer_out = layer_out[0, :, :, :]\n",
    "    layer_out = np.transpose(layer_out,(2, 0, 1))\n",
    "    return layer_out\n",
    "\n",
    "def get_SoftmaxWeights(model):\n",
    "    return model.layers[-1].get_weights()[0]\n",
    "\n",
    "def get_defects(defects, n = target_class):\n",
    "    \n",
    "    for i, key in enumerate(defects.keys()):\n",
    "        if i == n:\n",
    "            return key\n",
    "\n",
    "\"\"\"Load CNN Model here\"\"\"\n",
    "#model = load_model('New_defect_CNN.h5')\n",
    "\n",
    "model = model\n",
    "\n",
    "#no. of the last conv layer(can be found in model.summary() )\n",
    "last_conv_layer = -4\n",
    "\n",
    "image_size = 64, 64\n",
    "\n",
    "\"\"\"Load image file name here\"\"\"\n",
    "image_file = 'SJ_gauss_Vw'\n",
    "\n",
    "CAM_defects = {}\n",
    "\n",
    "## Still working on this - incorporating coordinate search & making it better and well documented \n",
    "## but feel free to optimize\n",
    "img = cv2.imread(image_file + '.png', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, image_size, interpolation = cv2.INTER_AREA)\n",
    "img_i = np.copy(img)\n",
    "img = image_preprocessing_cam(img, image_size) \n",
    "predictions = get_predictions(model, img)\n",
    "target_class = predictions.argmax()\n",
    "softmax_weights = get_SoftmaxWeights(model)\n",
    "conv_out = get_activation_maps(model, img, last_conv_layer)\n",
    "\n",
    "cam = np.zeros(shape = conv_out.shape[1:3], dtype = np.float32)\n",
    "\n",
    "for idx, weight in enumerate(softmax_weights[:, target_class]):\n",
    "    cam += weight * conv_out[idx, :, :]\n",
    "\n",
    "cam = (cam - np.amin(cam))/(np.amax(cam) - np.amin(cam))\n",
    "cam[np.where(cam < 0.5)] = 0\n",
    "cam = cv2.resize(cam, image_size)\n",
    "\n",
    "defect_class = get_defects(defects, target_class)\n",
    "\n",
    "max_coord = blob_log(cam, min_sigma=0.8)\n",
    "x, y = np.transpose(max_coord)[0:2,:]\n",
    "coordinates = list(zip(x,y))\n",
    "\n",
    "dictionary = OrderedDict()    \n",
    "dictionary['Image'] = img_i\n",
    "dictionary['Defect type'] = defect_class\n",
    "dictionary['Defect coordinates'] = coordinates\n",
    "dictionary['CAM'] = cam\n",
    "CAM_defects[image_file] = dictionary\n",
    "\n",
    "pickle.dump(CAM_defects, open(\"CAM_defects.pkl\", \"wb\"))\n",
    "#max_coord = blob_log(cam, min_sigma=0.5)\n",
    "#x, y = np.transpose(max_coord)[0:2,:]\n",
    "#coordinates = list(zip(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Class activation map with image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defect type: Vw\n",
      "defect coordinates (x, y): [(32.0, 30.0)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x25a98354320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, defect_type, defect_coordinates, cam = CAM_defects[image_file].values()\n",
    "#img = cv2.imread(image_file + '.png', cv2.IMREAD_GRAYSCALE)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(img, cmap = 'gray')\n",
    "ax1.set_title('Original image')\n",
    "ax2.imshow(cam, cmap = 'hot')\n",
    "ax2.imshow(img, cmap = 'gray', alpha = 0.5)\n",
    "ax2.set_title('Original image + CAM \\n class: ' + defect_type)\n",
    "\n",
    "print('defect type:', defect_type)\n",
    "print('defect coordinates (x, y):', str(defect_coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mo': 1, 'Sw': 0, 'Vs2': 4, 'Vw': 3, 'W2s2': 2, 'Ws': 5}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defects.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Sw', 'Mo', 'W2s2', 'Vw', 'Vs2', 'Ws'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defects.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_defects(defects, n = target_class):\n",
    "    \n",
    "    for i, key in enumerate(defects.keys()):\n",
    "        if i == n:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vw'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_defects(defects, target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(28.0, 29.0)]\n"
     ]
    }
   ],
   "source": [
    "max_coord = blob_log(cam, min_sigma=0.8)\n",
    "x, y = np.transpose(max_coord)[0:2,:]\n",
    "coordinates = list(zip(x,y))\n",
    "print(coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other stuff that I was trying - gradient class activation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-9da5a1c09d53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[0mpredicted_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m \u001b[0mcam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheatmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrad_cam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocessed_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"conv2d_36\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gradcam.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-172-9da5a1c09d53>\u001b[0m in \u001b[0;36mgrad_cam\u001b[1;34m(input_model, image, category_index, layer_name)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0mconv_output\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mgradient_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.framework import ops\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "def target_category_loss(x, category_index, nb_classes):\n",
    "    return tf.multiply(x, K.one_hot([category_index], nb_classes))\n",
    "\n",
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "\n",
    "def load_image(img_path):\n",
    "    \n",
    "    img = image.load_img(img_path, grayscale = True, target_size=(64, 64))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    #x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "def register_gradient():\n",
    "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
    "        @ops.RegisterGradient(\"GuidedBackProp\")\n",
    "        def _GuidedBackProp(op, grad):\n",
    "            dtype = op.inputs[0].dtype\n",
    "            return grad * tf.cast(grad > 0., dtype) * \\\n",
    "                tf.cast(op.inputs[0] > 0., dtype)\n",
    "\n",
    "def compile_saliency_function(model, activation_layer=\"conv2d_2\"):\n",
    "    input_img = model.input\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    layer_output = layer_dict[activation_layer].output\n",
    "    max_output = K.max(layer_output, axis=3)\n",
    "    saliency = K.gradients(K.sum(max_output), input_img)[0]\n",
    "    return K.function([input_img, K.learning_phase()], [saliency])\n",
    "\n",
    "def modify_backprop(model, name):\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({'Relu': name}):\n",
    "\n",
    "        # get layers that have an activation\n",
    "        layer_dict = [layer for layer in model.layers[1:]\n",
    "                      if hasattr(layer, 'activation')]\n",
    "\n",
    "        # replace relu activation\n",
    "        for layer in layer_dict:\n",
    "            if layer.activation == keras.activations.relu:\n",
    "                layer.activation = tf.nn.relu\n",
    "\n",
    "        # re-instanciate a new model\n",
    "        new_model = VGG16(weights='imagenet') ##########################################################\n",
    "    return new_model\n",
    "\n",
    "def deprocess_image(x):\n",
    "    '''\n",
    "    Same normalization as in:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "    '''\n",
    "    if np.ndim(x) > 3:\n",
    "        x = np.squeeze(x)\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "def grad_cam(input_model, image, category_index, layer_name):\n",
    "    model = Sequential()\n",
    "    model.add(input_model)\n",
    "\n",
    "    nb_classes = 6\n",
    "    target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "    model.add(Lambda(target_layer,\n",
    "                     output_shape = target_category_loss_output_shape))\n",
    "\n",
    "    loss = K.sum(model.layers[-1].output)\n",
    "    conv_output =  [l for l in model.layers[0].layers if l.name is layer_name][0].output\n",
    "    grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "    gradient_function = K.function([model.layers[0].input], [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis = (0, 1))\n",
    "    cam = np.ones(output.shape[0 : 2], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, :, i]\n",
    "\n",
    "    cam = cv2.resize(cam, (64, 64))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "\n",
    "    #Return to BGR [0..255] from the preprocessed image\n",
    "    image = image[0, :]\n",
    "    image -= np.min(image)\n",
    "    image = np.minimum(image, 255)\n",
    "\n",
    "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "    cam = np.float32(cam) + np.float32(image)\n",
    "    cam = 255 * cam / np.max(cam)\n",
    "    return np.uint8(cam), heatmap\n",
    "\n",
    "preprocessed_input = load_image('SJ.png')\n",
    "\n",
    "model = model\n",
    "\n",
    "predictions = model.predict(preprocessed_input)\n",
    "#top_1 = decode_predictions(predictions)[0][0]\n",
    "#print('Predicted class:')\n",
    "#print('%s (%s) with probability %.2f' % (top_1[1], top_1[0], top_1[2]))\n",
    "\n",
    "predicted_class = np.argmax(predictions)\n",
    "cam, heatmap = grad_cam(model, preprocessed_input, predicted_class, \"conv2d_36\")\n",
    "cv2.imwrite(\"gradcam.jpg\", cam)\n",
    "\n",
    "#register_gradient()\n",
    "#guided_model = modify_backprop(model, 'GuidedBackProp')\n",
    "#saliency_fn = compile_saliency_function(guided_model)\n",
    "#saliency = saliency_fn([preprocessed_input, 0])\n",
    "#gradcam = saliency[0] * heatmap[..., np.newaxis]\n",
    "#cv2.imwrite(\"guided_gradcam.jpg\", deprocess_image(gradcam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "model_path = model \n",
    "img_path = \"SJ.png\"\n",
    "output_path = \"Trail_Image.png\"\n",
    "\n",
    "def visualize_class_activation_map(model_path, img_path, output_path):\n",
    "        model = load_model(model_path)\n",
    "        original_img = cv2.imread(img_path, 1)\n",
    "        width, height, _ = original_img.shape\n",
    "\n",
    "        #Reshape to the network input shape (3, w, h).\n",
    "        img = np.array([np.transpose(np.float32(original_img), (2, 0, 1))])\n",
    "        \n",
    "        #Get the 512 input weights to the softmax.\n",
    "        class_weights = model.layers[-1].get_weights()[0]\n",
    "        final_conv_layer = model.get_layer(\"conv2d_36\")\n",
    "        #final_conv_layer = get_output_layer(model, \"conv5_3\")\n",
    "        get_output = K.function([model.layers[0].input], [final_conv_layer.output, model.layers[-1].output])\n",
    "        [conv_outputs, predictions] = get_output([img])\n",
    "        conv_outputs = conv_outputs[0, :, :, :]\n",
    "\n",
    "        #Create the class activation map.\n",
    "        cam = np.zeros(dtype = np.float32, shape = conv_outputs.shape[1:3])\n",
    "        for i, w in enumerate(class_weights[:, 1]):\n",
    "                cam += w * conv_outputs[i, :, :]\n",
    "        \n",
    "        cam /= np.max(cam)\n",
    "        cam = cv2.resize(cam, (height, width))\n",
    "        heatmap = cv2.applyColorMap(np.uint8(cam), cv2.COLORMAP_JET)\n",
    "        heatmap[np.where(cam < 0.2)] = 0\n",
    "        img = heatmap*0.5 + original_img\n",
    "        cv2.imwrite(output_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "##### add layers to CNN model: \n",
    "model.add(Conv2D(32,kernel_size=(5,5),strides=(1,1),\n",
    "                activation='relu',\n",
    "                input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(64,(5,5),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000,activation='relu'))\n",
    "model.add(Dense(num_classes,activation='softmax'))\n",
    "######\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "             optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40900 samples, validate on 10225 samples\n",
      "Epoch 1/50\n",
      "40900/40900 [==============================] - 283s 7ms/step - loss: 1.6054 - acc: 0.3772 - val_loss: 1.2119 - val_acc: 0.5668\n",
      "Epoch 2/50\n",
      "40900/40900 [==============================] - 279s 7ms/step - loss: 0.8499 - acc: 0.6784 - val_loss: 0.6669 - val_acc: 0.7566\n",
      "Epoch 3/50\n",
      "40900/40900 [==============================] - 273s 7ms/step - loss: 0.4930 - acc: 0.8068 - val_loss: 0.4115 - val_acc: 0.8365\n",
      "Epoch 4/50\n",
      "40900/40900 [==============================] - 271s 7ms/step - loss: 0.3457 - acc: 0.8667 - val_loss: 0.3731 - val_acc: 0.8498\n",
      "Epoch 5/50\n",
      "40900/40900 [==============================] - 273s 7ms/step - loss: 0.2912 - acc: 0.8860 - val_loss: 0.2777 - val_acc: 0.8920\n",
      "Epoch 6/50\n",
      "40900/40900 [==============================] - 273s 7ms/step - loss: 0.2624 - acc: 0.9003 - val_loss: 0.2308 - val_acc: 0.9099\n",
      "Epoch 7/50\n",
      "40900/40900 [==============================] - 272s 7ms/step - loss: 0.2321 - acc: 0.9101 - val_loss: 0.2453 - val_acc: 0.8965\n",
      "Epoch 8/50\n",
      "40900/40900 [==============================] - 270s 7ms/step - loss: 0.2138 - acc: 0.9176 - val_loss: 0.2147 - val_acc: 0.9176\n",
      "Epoch 9/50\n",
      "40900/40900 [==============================] - 268s 7ms/step - loss: 0.1913 - acc: 0.9276 - val_loss: 0.1988 - val_acc: 0.9217\n",
      "Epoch 10/50\n",
      "40900/40900 [==============================] - 22622s 553ms/step - loss: 0.1830 - acc: 0.9299 - val_loss: 0.1974 - val_acc: 0.9239\n",
      "Epoch 11/50\n",
      "40900/40900 [==============================] - 277s 7ms/step - loss: 0.1912 - acc: 0.9286 - val_loss: 0.4051 - val_acc: 0.8303\n",
      "Epoch 12/50\n",
      "40900/40900 [==============================] - 277s 7ms/step - loss: 0.1718 - acc: 0.9356 - val_loss: 0.1793 - val_acc: 0.9273\n",
      "Epoch 13/50\n",
      "40900/40900 [==============================] - 22084s 540ms/step - loss: 0.1580 - acc: 0.9424 - val_loss: 0.1753 - val_acc: 0.9293\n",
      "Epoch 14/50\n",
      "40900/40900 [==============================] - 1905s 47ms/step - loss: 0.1454 - acc: 0.9472 - val_loss: 0.1562 - val_acc: 0.9371\n",
      "Epoch 15/50\n",
      "40900/40900 [==============================] - 313s 8ms/step - loss: 0.1261 - acc: 0.9550 - val_loss: 0.1503 - val_acc: 0.9373\n",
      "Epoch 16/50\n",
      "40900/40900 [==============================] - 285s 7ms/step - loss: 0.1221 - acc: 0.9562 - val_loss: 0.1580 - val_acc: 0.9350\n",
      "Epoch 17/50\n",
      "40900/40900 [==============================] - 280s 7ms/step - loss: 0.1136 - acc: 0.9594 - val_loss: 0.2330 - val_acc: 0.9061\n",
      "Epoch 18/50\n",
      "40900/40900 [==============================] - 280s 7ms/step - loss: 0.1089 - acc: 0.9613 - val_loss: 0.1277 - val_acc: 0.9487\n",
      "Epoch 19/50\n",
      "40900/40900 [==============================] - 269s 7ms/step - loss: 0.0974 - acc: 0.9659 - val_loss: 0.1457 - val_acc: 0.9420\n",
      "Epoch 20/50\n",
      "40900/40900 [==============================] - 263s 6ms/step - loss: 0.1009 - acc: 0.9653 - val_loss: 0.1632 - val_acc: 0.9402\n",
      "Epoch 21/50\n",
      "40900/40900 [==============================] - 264s 6ms/step - loss: 0.0917 - acc: 0.9689 - val_loss: 0.1264 - val_acc: 0.9512\n",
      "Epoch 22/50\n",
      "40900/40900 [==============================] - 266s 6ms/step - loss: 0.0905 - acc: 0.9704 - val_loss: 0.1181 - val_acc: 0.9543\n",
      "Epoch 23/50\n",
      "40900/40900 [==============================] - 3070s 75ms/step - loss: 0.0785 - acc: 0.9737 - val_loss: 0.1269 - val_acc: 0.9495\n",
      "Epoch 24/50\n",
      "40900/40900 [==============================] - 3663s 90ms/step - loss: 0.0856 - acc: 0.9708 - val_loss: 0.1372 - val_acc: 0.9476\n",
      "Epoch 25/50\n",
      "40900/40900 [==============================] - 387s 9ms/step - loss: 0.0717 - acc: 0.9772 - val_loss: 0.1240 - val_acc: 0.9489\n",
      "Epoch 26/50\n",
      "40900/40900 [==============================] - 299s 7ms/step - loss: 0.0700 - acc: 0.9781 - val_loss: 0.1186 - val_acc: 0.9538\n",
      "Epoch 27/50\n",
      "40900/40900 [==============================] - 288s 7ms/step - loss: 0.0640 - acc: 0.9787 - val_loss: 0.1139 - val_acc: 0.9563\n",
      "Epoch 28/50\n",
      "40900/40900 [==============================] - 283s 7ms/step - loss: 0.0619 - acc: 0.9799 - val_loss: 0.1058 - val_acc: 0.9582\n",
      "Epoch 29/50\n",
      "40900/40900 [==============================] - 288s 7ms/step - loss: 0.0628 - acc: 0.9802 - val_loss: 0.1207 - val_acc: 0.9544\n",
      "Epoch 30/50\n",
      "40900/40900 [==============================] - 284s 7ms/step - loss: 0.0523 - acc: 0.9839 - val_loss: 0.0960 - val_acc: 0.9632\n",
      "Epoch 31/50\n",
      "40900/40900 [==============================] - 282s 7ms/step - loss: 0.0522 - acc: 0.9839 - val_loss: 0.0983 - val_acc: 0.9615\n",
      "Epoch 32/50\n",
      "40900/40900 [==============================] - 276s 7ms/step - loss: 0.0465 - acc: 0.9856 - val_loss: 0.0948 - val_acc: 0.9637\n",
      "Epoch 33/50\n",
      "40900/40900 [==============================] - 280s 7ms/step - loss: 0.0451 - acc: 0.9865 - val_loss: 0.1065 - val_acc: 0.9596\n",
      "Epoch 34/50\n",
      "40900/40900 [==============================] - 286s 7ms/step - loss: 0.0824 - acc: 0.9784 - val_loss: 0.1257 - val_acc: 0.9515\n",
      "Epoch 35/50\n",
      "40900/40900 [==============================] - 288s 7ms/step - loss: 0.0630 - acc: 0.9801 - val_loss: 0.1274 - val_acc: 0.9520\n",
      "Epoch 36/50\n",
      "40900/40900 [==============================] - 295s 7ms/step - loss: 0.0509 - acc: 0.9847 - val_loss: 0.1019 - val_acc: 0.9604\n",
      "Epoch 37/50\n",
      "40900/40900 [==============================] - 277s 7ms/step - loss: 0.0412 - acc: 0.9877 - val_loss: 0.0925 - val_acc: 0.9642\n",
      "Epoch 38/50\n",
      "40900/40900 [==============================] - 277s 7ms/step - loss: 0.0762 - acc: 0.9784 - val_loss: 0.0985 - val_acc: 0.9638\n",
      "Epoch 39/50\n",
      "40900/40900 [==============================] - 281s 7ms/step - loss: 0.0399 - acc: 0.9880 - val_loss: 0.1156 - val_acc: 0.9566\n",
      "Epoch 40/50\n",
      "40900/40900 [==============================] - 278s 7ms/step - loss: 0.0377 - acc: 0.9883 - val_loss: 0.0927 - val_acc: 0.9649\n",
      "Epoch 41/50\n",
      "40900/40900 [==============================] - 273s 7ms/step - loss: 0.0514 - acc: 0.9862 - val_loss: 0.1502 - val_acc: 0.9464\n",
      "Epoch 42/50\n",
      "40900/40900 [==============================] - 267s 7ms/step - loss: 0.0516 - acc: 0.9843 - val_loss: 0.1164 - val_acc: 0.9583\n",
      "Epoch 43/50\n",
      "40900/40900 [==============================] - 265s 6ms/step - loss: 0.0436 - acc: 0.9869 - val_loss: 0.1041 - val_acc: 0.9620\n",
      "Epoch 44/50\n",
      "40900/40900 [==============================] - 270s 7ms/step - loss: 0.0366 - acc: 0.9891 - val_loss: 0.1010 - val_acc: 0.9610\n",
      "Epoch 45/50\n",
      "40900/40900 [==============================] - 280s 7ms/step - loss: 0.0339 - acc: 0.9903 - val_loss: 0.1123 - val_acc: 0.9606\n",
      "Epoch 46/50\n",
      "40900/40900 [==============================] - 279s 7ms/step - loss: 0.0323 - acc: 0.9906 - val_loss: 0.1145 - val_acc: 0.9576\n",
      "Epoch 47/50\n",
      "40900/40900 [==============================] - 276s 7ms/step - loss: 0.0308 - acc: 0.9911 - val_loss: 0.1021 - val_acc: 0.9620\n",
      "Epoch 48/50\n",
      "40900/40900 [==============================] - 268s 7ms/step - loss: 0.0289 - acc: 0.9915 - val_loss: 0.1084 - val_acc: 0.9604\n",
      "Epoch 49/50\n",
      "40900/40900 [==============================] - 269s 7ms/step - loss: 0.0278 - acc: 0.9921 - val_loss: 0.0943 - val_acc: 0.9652\n",
      "Epoch 50/50\n",
      "40900/40900 [==============================] - 271s 7ms/step - loss: 0.0270 - acc: 0.9920 - val_loss: 0.1086 - val_acc: 0.9622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bb306e9c88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self,logs={}):\n",
    "        self.acc=[]\n",
    "    \n",
    "    def on_epoch_end(self,batch,logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "\n",
    "history=AccuracyHistory()\n",
    "        \n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         verbose=1,\n",
    "         validation_data=(x_test,y_test),\n",
    "         callbacks=[history])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
